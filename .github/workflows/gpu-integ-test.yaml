name: Run GPU Integration Tests

on:
  push:
    branches:
     - main
  pull_request:
  workflow_dispatch:

env:
  ACTIONS_RUNNER_DEBUG: true
  ACTIONS_STEP_DEBUG: true

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  pytorch-integration-local:
    runs-on: [single-gpu, nvidia-gpu, t4, ci]
    env:
      AWS_REGION: us-east-1
    steps:
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Check permissions
      run: |
        import os
        def check_directory_permissions(directory_path):
          permissions = os.stat(directory_path).st_mode
          print(f"Permissions of the directory: {directory_path}")
          print(f"Read permission: {'Yes' if permissions & 0o400 else 'No'}")
          print(f"Write permission: {'Yes' if permissions & 0o200 else 'No'}")
          print(f"Execute permission: {'Yes' if permissions & 0o100 else 'No'}")

        directory_path = "/tmp"
        check_directory_permissions(directory_path)
      shell: python
    - uses: actions/checkout@v4.1.1
    - name: Docker Setup Buildx
      uses: docker/setup-buildx-action@v3.0.0
    - name: Docker Build
      run: make inference-pytorch-gpu
    - name: List images
      run: docker images
    - name: Install hub
      run: pip install -U "huggingface_hub[cli]"
    - name: Download dummy model
      run: huggingface-cli download distilbert/distilbert-base-uncased --local-dir /tmp/distilbert
    - name: Container dry run
      run: |
        docker run
          -v /tmp/distilbert:/tmp/distilbert
          -e HF_MODEL_DIR="tmp/distilbert"
          -e HF_TASK="text-classification"
          -d integration-test-pytorch:gpu
    - name: Stop container
      run: make stop-all
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install tox & uv
      run: pip install uv tox
    - name: Run local integration tests
      run: tox -e torch-integration-local-gpu
  pytorch-integration-remote:
    runs-on: [single-gpu, nvidia-gpu, t4, ci]
    env:
      AWS_REGION: us-east-1
    steps:
    - uses: actions/checkout@v4.1.1
    - name: Docker Setup Buildx
      uses: docker/setup-buildx-action@v3.0.0
    - name: Docker Build
      run: make inference-pytorch-gpu
    - name: List images
      run: docker images
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install tox & uv
      run: pip install uv tox
    - name: Run remote integration tests
      run: tox -e torch-integration-remote-gpu -- -n 4